---
- id: snykio:maven:org.apache.hive:hive-common:30638
  title: Information Exposure
  description: |
    [org.apache.hive:hive-common][1] is a reading, writing, and managing
    large datasets residing in distributed storage using SQL.

    Affected versions of this package are vulnerable to Information
    Exposure. This vulnerability relates to a replay attack due to
    authenticating twice within a short period of time, when the context
    root is requested.



    [1]: https://hive.apache.org
  affected_package: org.apache.hive:hive-common
  vulnerable_versions:
  - ">= 1.2.0 < 2.2.0"
  severity: medium
  package_manager: maven
  cwe:
  - CWE-200
  disclosed_date: 2016-10-31
  created_date: 2016-10-31
  last_modified_date: 2016-10-31
  credit:
  - Unknown
  references:
  - https://github.com/apache/hive/commit/f42021125b79ff8c9f6d52777c6c67738c07d675
  - https://issues.apache.org/jira/browse/HIVE-14984
  source_url: https://snyk.io/vuln/SNYK-JAVA-ORGAPACHEHIVE-30638
- id: snykio:maven:org.apache.hive:hive-common:31662
  title: Arbitrary File Write
  description: "[`org.apache.hive:hive-common`][1] acilitates reading, writing, and\nmanaging
    large datasets residing in distributed storage using SQL.\n\nApache Hive is vulnerable
    to Arbitrary File Write via the File Transfer\nProtocol (FTP) client functionality.
    Hive gives an SQL-like interface to\nquery data stored in various databases and
    file systems that integrate\nwith Hadoop. Among other things, it supports copying
    data from FTP\nservers, using the [COPY-FROM-FTP command][2].\n\n    COPY FROM
    FTP host [USER user [PWD password]] [DIR directory] [FILES files_wildcard]\n      [TO
    [LOCAL] target_directory] [options]\n    \n    options:\n      OVERWRITE | NEW\n
    \     SUBDIR\n      SESSIONS num  \n\nA possible attack can be overriding the
    ssh authorized\\_keys file for\nthe root user, making it possible to login as
    root later on. Assumming\nthat Apache Hive instance connects to the attacker\\'s
    malicious FTP\nserver, to download some merchant data daily, by using the following\nquery:\n\n
    \   COPY FROM FTP remote.merchant.domain.com\n      USER 'foo' PWD '***'\n      DIR
    data/sales/in FILES  '.*'\n      TO /data/sales/raw OVERWRITE\n\nThe malicious
    FTP server would send back *path traversal* filenames to\nthe client. For instance,
    responding to a LIST command with\n`../../../../../../../home/root/.ssh/authorized_keys`.\n\nWhen
    Hive executes the above statement (assuming it’s running as root),\nroot’s `authorized_keys`
    ssh file will be overwritten with one known by\nthe attacker.\n\n\n\n[1]: https://hive.apache.org\n[2]:
    http://www.hplsql.org/copy-from-ftp\n\\nFTP is a standard network protocol used
    to transfer files between a\nclient and server. Out of the box, it does not offer
    a *download folder*\ncommand, but it does allow the following:\n\n1.  Listing
    all of the files in a remote folder (`LIST` or `NLST` FTP\n    commands)\n2.  For
    each file in the list results above: Download the file and save\n    it to a local
    folder (`GET` or `MGET` FTP commands)\n\nThe following is an example of some Java
    code downloading a folder,\nusing the Apache commons-net library:\n\n    private
    void downloadDirectory(FTPClient ftpClient, String remoteDir, String localDir)
    throws IOException\n    {\n      FTPFile[] subFiles = ftpClient.listFiles(remoteDir);\n
    \     for (FTPFile aFile : subFiles)\n      {\n        if (!aFile.isDirectory())\n
    \       {\n           String remoteFile = ftpClient.printWorkingDirectory() +
    File.separator + aFile.getName();\n           String localFile = localDir + File.separator
    + aFile.getName();\n    \n           OutputStream downloadedStream = new BufferedOutputStream(new
    FileOutputStream(new File(localFile)));\n           boolean success = ftpClient.retrieveFile(remoteFile,
    downloadedStream);\n           outputStream.close();            \n        }\n
    \     }\n    }\n{: .language-java}\n\nThe code above, iterates over each file
    returned by the server, and\ndownloads it into a local destination folder. So
    for example, if the\nfirst file in the remote folder is named `passwd`, and the
    local\ndestination folder is `/var/data/sync/`, it\\'d end up downloading the\nfile
    to `/var/data/sync/passwd`.\n\nBut if the FTP server turns malicious, and instead
    of responding to the\nLIST command with `passwd`, it responds with `../../../../etc/passwd`
    as\nthe filename. The code above will end up placing the file into\n`/var/data/sync/../../../../etc/passwd`,
    practically overwriting\n`/etc/passwd` with the newly downloaded file.\n\nFor
    more information you can check out our [blog post][1].\n\n\n\n[1]: https://snyk.io/blog/attacking-an-ftp-client/\n"
  affected_package: org.apache.hive:hive-common
  vulnerable_versions:
  - ">= 2.1.0 < 2.3.3"
  severity: low
  package_manager: maven
  cve:
  - CVE-2018-1315
  cwe:
  - CWE-269
  disclosed_date: 2018-04-04
  created_date: 2018-04-04
  last_modified_date: 2018-04-04
  credit:
  - Snyk Security Research Team
  references:
  - https://snyk.io/blog/attacking-an-ftp-client/
  source_url: https://snyk.io/vuln/SNYK-JAVA-ORGAPACHEHIVE-31662
- id: snykio:maven:org.apache.hive:hive-common:32203
  title: Arbitrary Files Access
  description: |
    [org.apache.hive:hive-common][1] is a package for reading, writing, and
    managing large datasets residing in distributed storage using SQL.

    Affected versions of this package are vulnerable to Arbitrary Files
    Access. A malicious user might use any xpath UDFs to expose the content
    of a file on the machine running `HiveServer2` owned by a `HiveServer2`
    user (usually hive) if `hive.server2.enable.doAs=false`.



    [1]: https://hive.apache.org
  affected_package: org.apache.hive:hive-common
  vulnerable_versions:
  - ">= 0.8.0 < 2.3.3"
  severity: low
  package_manager: maven
  cve:
  - CVE-2018-1284
  cwe:
  - CWE-284
  disclosed_date: 2018-04-09
  created_date: 2018-04-09
  last_modified_date: 2018-04-09
  credit:
  - Unknown
  references:
  - https://github.com/apache/hive/commit/b0a58d245875dc1b3ac58a7cf1a61d3b17805e96
  - https://lists.apache.org/thread.html/29184dbce4a37be2af36e539ecb479b1d27868f73ccfdff46c7174b4@%3Cdev.hive.apache.org%3E
  source_url: https://snyk.io/vuln/SNYK-JAVA-ORGAPACHEHIVE-32203
- id: snykio:maven:org.apache.hive:hive-common:474415
  title: Improper Access Control
  description: |
    [org.apache.hive:hive-common][1] is a reading, writing, and managing
    large datasets residing in distributed storage using SQL.

    Affected versions of this package are vulnerable to Improper Access
    Control. When in SQL standards based authorization mode, the package
    does not properly check the file permissions for (1) import and (2)
    export statements, which allows remote authenticated users to obtain
    sensitive information via a crafted URI.



    [1]: https://hive.apache.org
  affected_package: org.apache.hive:hive-common
  vulnerable_versions:
  - ">= 0.8.0 < 0.13.1"
  severity: low
  package_manager: maven
  cve:
  - CVE-2014-0228
  cwe:
  - CWE-284
  disclosed_date: 2014-11-16
  created_date: 2015-04-05
  last_modified_date: 2015-04-05
  credit:
  - Thejas Nair of Hortonworks
  references:
  - http://mail-archives.apache.org/mod_mbox/hive-user/201406.mbox/%3CCABgNGzeN7E+9d=YV5yvnKA7wmSx1op_avtUjPcPtDaR6DLJM6g@mail.gmail.com%3E
  - https://github.com/apache/hive/commit/5831be0c57520d2d8c7a2ae5fa1499b5089cf927
  - https://github.com/apache/hive/commit/9ef3522f632a0abb5465eca849188776c1b4db13
  - https://github.com/apache/hive/commit/c3d7083b7605d1753946c4c4411e3a3241ea7ffe
  source_url: https://snyk.io/vuln/SNYK-JAVA-ORGAPACHEHIVE-474415
